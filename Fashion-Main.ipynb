{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch\n",
    "\n",
    "This is the neural "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the model dependencies and data. In the repo, the train data has been divided\n",
    "because of github file size limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m train_data_part1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/path/NumNetworks - FashionMNIST/Data/mnist_train/fashion-mnist_train1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_part1 = pd.read_csv('C:/Users/path/NumNetworks - FashionMNIST/Data/mnist_train/fashion-mnist_train1.csv')\n",
    "train_data_part2 = pd.read_csv('C:/Users/path/NumNetworks - FashionMNIST/Data/mnist_train/fashion-mnist_train2.csv')\n",
    "\n",
    "train_data = pd.concat([train_data_part1, train_data_part2])\n",
    "\n",
    "test_data = pd.read_csv('C:/Users/path/NumNetworks - FashionMNIST/Data/mnist_test/fashion-mnist_test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data and shuffling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) 785 60000\n",
      "(10000, 785) 785 60000\n",
      "(785, 60000) 785 60000\n",
      "(60000,) (784, 60000)\n",
      "(785, 10000) 785 10000\n",
      "(10000,) (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(train_data)\n",
    "m, n = train_data.shape\n",
    "print(train_data.shape, n, m )\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "m2, n2 =  test_data.shape\n",
    "print(test_data.shape, n, m )\n",
    "np.random.shuffle(test_data)\n",
    "\n",
    "data_train = train_data.T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "print(data_train.shape, n, m )\n",
    "print(Y_train.shape, X_train.shape)\n",
    "\n",
    "data_test = test_data.T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n2]\n",
    "X_test = X_test / 255.\n",
    "print(data_test.shape, n2, m2 )\n",
    "print(Y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions declarations\n",
    "\n",
    "In this part, we declare the functions needed for the neural network. \n",
    "\n",
    "- **Inizialize parameters** creates random parameters ranging from 0 to 1. Subtracting -0.5 helps us to have also negative parameters. \n",
    "- **ReLu** defines the activation function. \n",
    "- **softmax** is the prediction criteria. Since with exponentials the risk of overflow is non-trivial, we subtract Z by the max(Z), given the fact that softmax(x)=softmax(x+c).\n",
    "- **forward_prop** defines the forward propragation of our  method. \n",
    "- **ReLu_deriv(Z)**: The derivative of the ReLu, which is simply either 1 or 0, dependent on the Z value. \n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1 = np.random.rand(64, 784) - 0.5\n",
    "    b1 = np.random.rand(64, 1) - 0.5\n",
    "    W2 = np.random.rand(32, 64) - 0.5\n",
    "    b2 = np.random.rand(32, 1) - 0.5\n",
    "    W3 = np.random.rand(10, 32) - 0.5\n",
    "    b3 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    Z_shift = Z - np.max(Z, axis=0)\n",
    "    exp_Z = np.exp(Z_shift)\n",
    "    A = exp_Z / np.sum(exp_Z, axis=0)\n",
    "    return A\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = ReLU(Z2)\n",
    "    Z3 = W3.dot(A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ3 = A3 - one_hot_Y\n",
    "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    db3 = 1 / m * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = W3.T.dot(dZ3) * ReLU_deriv(Z2)\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    W3 -= alpha * dW3\n",
    "    b3 -= alpha * db3\n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A):\n",
    "    return np.argmax(A, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2, W3, b3 = initialize_parameters()\n",
    "    \n",
    "    for i in range(1, iterations+1):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3 = update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            predictions = get_predictions(A3)\n",
    "            print(\"Accuracy:\", get_accuracy(predictions, Y))\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "[8 8 7 ... 5 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.41146666666666665\n",
      "Iteration: 20\n",
      "[9 9 9 ... 6 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.5974666666666667\n",
      "Iteration: 30\n",
      "[9 9 5 ... 6 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.6378666666666667\n",
      "Iteration: 40\n",
      "[9 9 5 ... 6 1 4] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.6560833333333334\n",
      "Iteration: 50\n",
      "[9 9 5 ... 6 1 4] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.6710666666666667\n",
      "Iteration: 60\n",
      "[9 9 5 ... 6 1 4] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.6845666666666667\n",
      "Iteration: 70\n",
      "[9 9 5 ... 6 1 4] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.6939166666666666\n",
      "Iteration: 80\n",
      "[9 9 5 ... 8 1 4] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7026833333333333\n",
      "Iteration: 90\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7093333333333334\n",
      "Iteration: 100\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7167166666666667\n",
      "Iteration: 110\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7219833333333333\n",
      "Iteration: 120\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7270833333333333\n",
      "Iteration: 130\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7307333333333333\n",
      "Iteration: 140\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7363833333333333\n",
      "Iteration: 150\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7427333333333334\n",
      "Iteration: 160\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.75025\n",
      "Iteration: 170\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7524\n",
      "Iteration: 180\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.75485\n",
      "Iteration: 190\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7589\n",
      "Iteration: 200\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7624166666666666\n",
      "Iteration: 210\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7658166666666667\n",
      "Iteration: 220\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7681833333333333\n",
      "Iteration: 230\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7730666666666667\n",
      "Iteration: 240\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7700666666666667\n",
      "Iteration: 250\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.77525\n",
      "Iteration: 260\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7789166666666667\n",
      "Iteration: 270\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7820333333333334\n",
      "Iteration: 280\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7827166666666666\n",
      "Iteration: 290\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7845\n",
      "Iteration: 300\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7864166666666667\n",
      "Iteration: 310\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7886833333333333\n",
      "Iteration: 320\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7831333333333333\n",
      "Iteration: 330\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.79235\n",
      "Iteration: 340\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7945833333333333\n",
      "Iteration: 350\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7977833333333333\n",
      "Iteration: 360\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7993166666666667\n",
      "Iteration: 370\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8001833333333334\n",
      "Iteration: 380\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.7993166666666667\n",
      "Iteration: 390\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8003\n",
      "Iteration: 400\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8055\n",
      "Iteration: 410\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8082166666666667\n",
      "Iteration: 420\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8087666666666666\n",
      "Iteration: 430\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.80525\n",
      "Iteration: 440\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8097166666666666\n",
      "Iteration: 450\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8104833333333333\n",
      "Iteration: 460\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8093666666666667\n",
      "Iteration: 470\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8114833333333333\n",
      "Iteration: 480\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8131333333333334\n",
      "Iteration: 490\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.81205\n",
      "Iteration: 500\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8125666666666667\n",
      "Iteration: 510\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8152166666666667\n",
      "Iteration: 520\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8096166666666667\n",
      "Iteration: 530\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8197666666666666\n",
      "Iteration: 540\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8185666666666667\n",
      "Iteration: 550\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8214166666666667\n",
      "Iteration: 560\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8137333333333333\n",
      "Iteration: 570\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8212833333333334\n",
      "Iteration: 580\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8172166666666667\n",
      "Iteration: 590\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8241833333333334\n",
      "Iteration: 600\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8234333333333334\n",
      "Iteration: 610\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8224\n",
      "Iteration: 620\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.81885\n",
      "Iteration: 630\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8265833333333333\n",
      "Iteration: 640\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8274166666666667\n",
      "Iteration: 650\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8279666666666666\n",
      "Iteration: 660\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8234666666666667\n",
      "Iteration: 670\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8233833333333334\n",
      "Iteration: 680\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8291666666666667\n",
      "Iteration: 690\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8283166666666667\n",
      "Iteration: 700\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8286333333333333\n",
      "Iteration: 710\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8276166666666667\n",
      "Iteration: 720\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8313833333333334\n",
      "Iteration: 730\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8298166666666666\n",
      "Iteration: 740\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8275333333333333\n",
      "Iteration: 750\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8297333333333333\n",
      "Iteration: 760\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.83105\n",
      "Iteration: 770\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8320666666666666\n",
      "Iteration: 780\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8325\n",
      "Iteration: 790\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.83355\n",
      "Iteration: 800\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8314333333333334\n",
      "Iteration: 810\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.83505\n",
      "Iteration: 820\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8365\n",
      "Iteration: 830\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8374\n",
      "Iteration: 840\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8381333333333333\n",
      "Iteration: 850\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8385666666666667\n",
      "Iteration: 860\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8384666666666667\n",
      "Iteration: 870\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8308666666666666\n",
      "Iteration: 880\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8389166666666666\n",
      "Iteration: 890\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8384833333333334\n",
      "Iteration: 900\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.83955\n",
      "Iteration: 910\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.83845\n",
      "Iteration: 920\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8374166666666667\n",
      "Iteration: 930\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8400166666666666\n",
      "Iteration: 940\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8394833333333334\n",
      "Iteration: 950\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8391166666666666\n",
      "Iteration: 960\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8395333333333334\n",
      "Iteration: 970\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8403166666666667\n",
      "Iteration: 980\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.8405333333333334\n",
      "Iteration: 990\n",
      "[9 9 5 ... 8 1 6] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.84085\n",
      "Iteration: 1000\n",
      "[9 9 5 ... 8 1 2] [9 9 5 ... 8 1 2]\n",
      "Accuracy: 0.84105\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, 0.25, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
    "    _, _, _, _, _, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "    predictions = get_predictions(A3)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 3 ... 2 9 5] [3 5 3 ... 6 9 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8363"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = make_predictions(X_test, W1, b1, W2, b2, W3, b3)\n",
    "get_accuracy(test_prediction, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
